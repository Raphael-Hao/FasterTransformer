[ft_instance_hyperparameter]
max_batch_size=256
max_seq_len=1024 ; The sequence length of position embedding table, should move to model hyper-parameter
beam_width=1 ; beam width for beam search
top_k=1 ; k value for top k sampling
top_p=0 ; p value for top p sampling
temperature=1.0 ; Use for sampling
repetition_penalty=1.0 ; Use for sampling
presence_penalty=0.0  ; Only one of repetition_penalty and presence_penalty are allowed.
tensor_para_size=8
pipeline_para_size=1
data_type=fp16
sparse=0
int8_mode=0
enable_custom_all_reduce=0
model_name=Megatron_530B
; model_name=gpt_124M
; model_name=megatron_345M
; model_name=megatron_1.3B_adapter
; model_name=gpt_89B
; model_name=megatron_20B
; model_name=gpt_175B
; model_name=opt_125M
; model_name=opt_350M
; model_name=bloom_560M
; model_name=self_defined
; model_dir=/workspace/gpt3-6.7b/99.999/1-gpu
; model_dir=/workspace/gpt3_89b/1-gpu
model_dir=../models/megatron-models/c-model/345m/1-gpu/
len_penalty=0.0
beam_search_diversity_rate=0.0
shared_contexts_ratio=1.0
use_ffn=true

[request]
request_batch_size=256
request_output_len=800
return_log_probs=false  ; return the output log probs and cumulative log probs.
context_log_probs=false ; include input contexts in the cumulative log probability computation.
remove_padding=true
context_embeddings=true

[gpt_124M]
head_num=12
size_per_head=64
vocab_size=50257
decoder_layers=12
start_id=50256
end_id=50256
inter_size=3072
num_tasks=3 ;optional
prompt_learning_start_id=50257 ;optional
prompt_learning_type=3 ;optional

[megatron_345M]
head_num=16
size_per_head=64
vocab_size=50304
decoder_layers=1
start_id=50256
end_id=50256
inter_size=4096

[megatron_1.3B]
head_num=32
size_per_head=64
vocab_size=50304
decoder_layers=1
start_id=50256
end_id=50256
inter_size=8192

[megatron_6.7B]
head_num=32
size_per_head=128
vocab_size=51200
decoder_layers=1
start_id=50256
end_id=50256
inter_size=16384

[megatron_20B]
head_num=48
size_per_head=128
vocab_size=51200
decoder_layers=1
start_id=50256
end_id=50256
inter_size=24576

[gpt_89B]
head_num=96
size_per_head=128
vocab_size=51200
decoder_layers=1
inter_size=49152
start_id=50256
end_id=50256

[gpt_175B]
head_num=96
size_per_head=128
vocab_size=51200
decoder_layers=1
start_id=50256
end_id=50256
inter_size=49152

[Megatron_530B]
head_num=128
size_per_head=160
vocab_size=51200
decoder_layers=1
start_id=50256
end_id=50256
inter_size=81920

